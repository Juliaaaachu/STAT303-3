{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Project proposal\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. Please answer the following questions as part of your project proposal.\n",
    "\n",
    "2. Write your answers in the *Markdown* cells of the Jupyter notebook. You don't need to write any code, but if you want to, you may use the *Code* cells.\n",
    "\n",
    "3. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "4. The project proposal is worth 8 points, and is due on **18th April 2023 at 11:59 pm**. \n",
    "\n",
    "5. You must make one submission as a group, and not individually.\n",
    "\n",
    "6. Maintaining a GitHub repository is optional, though encouraged for the project.\n",
    "\n",
    "7. Share the link of your project's GitHub repository [here](https://docs.google.com/spreadsheets/d/1khao3unpj_vsx4kOSg_Zzo77YK1UWL2w73Oa0aAirOo/edit#gid=0) (optional)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "# 1) Team name\n",
    "WIP\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16fccc9b",
   "metadata": {},
   "source": [
    "# 2) Member names\n",
    "Julia Chu, William Pattie, Victoria Shi, Yiru Zhang\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220a6528",
   "metadata": {},
   "source": [
    "# 3) Link to the GitHub repository (optional)\n",
    "Share the link of the team's project repository on GitHub.\n",
    "\n",
    "https://github.com/Juliaaaachu/STAT303-3\n",
    "\n",
    "Also, put the link of your project's GitHub repository [here](https://docs.google.com/spreadsheets/d/1khao3unpj_vsx4kOSg_Zzo77YK1UWL2w73Oa0aAirOo/edit#gid=0).\n",
    "\n",
    "We believe there is no harm in having other teams view your GitHub repository. However, if you don't want anyone to see your team's work, you may make the repository *Private* and add your instructor and graduate TA as *Colloborators* in it.\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c1a490",
   "metadata": {},
   "source": [
    "# 4) Topic\n",
    "Home Credit Default Risk\n",
    "\n",
    "*(0 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9403cdfb",
   "metadata": {},
   "source": [
    "# 5) Problem statement\n",
    "\n",
    "*(4 points)*\n",
    "\n",
    "Explain the problem statement. The problem statement must include:\n",
    "\n",
    "## 5a) The problem",
    "\n",
    "Many people who are looking to own a home must go through a bank and get a loan in order to afford their home. When the bank gives out a loan to these potential homeowners, the banks are taking a risk: the people given the money may not be able to repay the loan. Given this risk, it is important for banks to properly vet people they grant loans to so they can ensure that people who are deserving of a loan can get their loan correctly, and the bank can be more confident they will get their loaned money back. We will be analyzing previous data on people who got loans and whether or not they defaulted to ensure that banks can be confident they are giving the loans to those who deserve them the most."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0dee45",
   "metadata": {},
   "source": [
    "## 5b) Type of response\n",
    "Is it about predicting a continuous response or a binary response or a combination of both?\n",
    "The response variable is a binary variable which is 1 if the person defaults on the loan and 0 if the person does not default on the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8cb75b",
   "metadata": {},
   "source": [
    "## 5c) Performance metric\n",
    "How will you assess model accuracy?\n",
    "\n",
    "  - If it is a classification problem, then which measure(s) will you optimize for your model – precision, recall, false negative rate (FNR), accuracy, ROC-AUC etc., and why?\n",
    "  - If it is a regression problem, then which measure(s) will you optimize for your model – RMSE (Root mean squared error), MAE (mean absolute error), maximum absolute error etc., and why?",
    "Our main metric to assess model accuracy will be the area under the ROC curve. This tells the odds that our model predicts a random observation who actually defaults is more likely to default than a random observation who does not default. This is how previous people who have used this dataset assessed their model performance.",
    "\n",
    "One other metrics that will be important to our tuning will be the recall metric, which is important to maximize as from the banks perspective, false negatives (giving a loan to someone who defaults) are likely more costly than false positives (not giving a loan to someone who won't default), so avoiding false negatives are especially important. Another metric to maximize is the precision metric, which ensures that while we are maximizing the recall, we are not just predicting most observations as defaults and getting too many false negatives, as this would prevent valuable homeowners from getting loans. To relate both of these metrics, we can try to maximize area under the precision and recall curve."

   ]
  },
  {
   "cell_type": "markdown",
   "id": "57701e9e",
   "metadata": {},
   "source": [
    "## 5d) Naive model accuracy\n",
    "What is the accuracy of the naive model (Standard deviation of response in case of continuous response / proportion of the majority class in case of classification model)\n",
    "In running the naive model (which simply predicts every observation in the dataset as 0), our model gets an ROC_AUC of 0.5, a recall of 0, and a precision of 0. The raw accuracy score, or proportion of the majority class 0, is 91.9%, but we are not using accuracy in our model since the vast majority of observations do not default."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb2d4f2",
   "metadata": {},
   "source": [
    "# 6) Data\n",
    "\n",
    "## 6a) Source\n",
    "What data sources will you use, and how will the data help solve the problem? Explain.\n",
    "If the data is open source, share the link of the data.\n",
    "\n",
    "*(0.5 point)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "554e29cf",
   "metadata": {},
   "source": [
    "The project will primarily utilize [Kaggle](https://www.kaggle.com/competitions/home-credit-default-risk/overview), a reputable public data science community, as its main data source. The dataset, initially provided by Home Credit, a non-bank financial institution, for educational and research purposes, will be pivotal in assessing customer repayment capability. The team's objective is to discern patterns, trends, and anomalies within the data that could potentially indicate borrowers' inability to repay loans. Through this analysis, our team aims to develop a robust detection system that empowers relevant stakeholders to identify and flag suspicious transactions, thereby mitigating financial losses and safeguarding future financial endeavors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bee818",
   "metadata": {},
   "source": [
    "## 6b) Response & predictors\n",
    "What is the response, and mention some of the predictors.\n",
    "\n",
    "*(0.5 point)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "92a37ac1",
   "metadata": {},
   "source": [
    "The \"target\" column in the dataset serves as the response variable, taking on either the value of 1, which indicates that the client (associated with a row of the data) has encountered payment difficulties and is flagged as a fraud in the sample, or the value of 0 (all other cases). The dataset consists of 122 predictors, including basic demographic information such as client gender, car ownership, total income, as well as details about their financial credit status, months of balance, and other financial information, etc. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb561c3",
   "metadata": {},
   "source": [
    "## 6c) Size\n",
    "What is the number of continuous predictors, categorical predictors, and observations in your dataset(s). If you are using multiple datasets, please provide the information for each dataset. When counting predictors, count only those that have sufficient non-missing values, and will be useful.\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01d85299",
   "metadata": {},
   "source": [
    "The dataset includes a total of 307,511 observations, there are 106 continuous predictors and 16 categorical predictors. The proportion of 0s and 1s in the 'target' column is 0.919271 (91.93%) and 0.080729 (8.07%) respectively, which indicates that the majority of clients in the dataset(s) do not encounter payment difficulties. These statistics provide important insights for understanding the characteristics of the dataset(s) and can inform model development. \n",
    "\n",
    "Based on the large size of the dataset and potential limitations in computational hardware, it may be necessary to subset the data during model development to ensure efficient processing. However, the specific methods and considerations for data subsetting will be thoroughly explained in the report. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0450286f",
   "metadata": {},
   "source": [
    "# 7) Exisiting solutions\n",
    "Are there existing solutions of your problem? Almost all Kaggle datasets have exisiting solutions. If yes, then how do you plan to build up on those solutions? **What is the highest model accuracy / performance achieved in the existing solutions?**\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f498864a",
   "metadata": {},
   "source": [
    "\n",
    "Based on the Kaggle competition website provided, it is evident that the Home Credit Default Risk problem has existing solutions. The highest model accuracy or performance achieved in the existing solutions is approximately 81.7% on the public leaderboard and 80.5% on the private leaderboard. The top performers achieved these high accuracy scores using various machine learning techniques, such as XGBoost, LightGBM, and neural networks, or an ensemble of multiple methods.\n",
    "\n",
    "To build upon these existing solutions, we will first gain a general idea of them and assess their applicability within our project scope. For example, if too much deep learning or neural learning is involved, they are probably not applicable to our project. If they only feature certain proportions,  we will exclude those methods. For techniques we have learned and understood, we will \"nitpick\" on them and identify potential areas for improvement, especially related to techniques such as cross-validation to find the best degree, fine-tuning hyperparameters, and others. Finally, we will use their approaches as a reference for our data preprocessing, feature engineering, and model selection.\n",
    "\n",
    "Thus, we aim to find the optimal point in the trade-off between precision and recall and, meanwhile, to explore how far we can achieve higher accuracy. Furthermore, we will evaluate the potential impact of our project, considering how it could be applied in the real world to help lenders assess credit risk and make better lending decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a845f",
   "metadata": {},
   "source": [
    "# 8) Stakeholders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39c782c",
   "metadata": {},
   "source": [
    "Who are the stakeholders, and how will your project benefit them? Explain.\n",
    "\n",
    "*(1 point)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea9b0d5",
   "metadata": {},
   "source": [
    "- The Home Credit Company (managing roles)\n",
    "    - The company itself posted the dataset on Kaggle and initiated the ‘competition’ to have more people figure out how to predict their clients' repayment abilities. This shows that they really want to know what factors are associated with their clients' repayment abilities. The repayment abilities are important to this company because they want the loans that they gave out to be returned to them so that they do not lose money (or even earn some interest). Knowing the repayment abilities of their clients can also help the company make their future financial plans (eg. increase/decrease interest rate, etc).\n",
    "- The ‘bank tellers’\n",
    "    - Similar to the people in the banks who directly serve the customers, in the Home Credit sites, there are also employees who handle the loans for the clients. Besides the managers who make big plans, the tellers also need to know whether or not to give a client the loan based on the information they know. Firstly, because they are the ones who really interact with the clients and make evaluations of the clients' repayment abilities. Secondly, because they are the ones blamed if they predict the repayment ability wrong. They are considered as a separate stakeholder because the managers work in headquarters while the tellers are in the ‘field’ and their information might not be the same. \n",
    "- The clients \n",
    "    - The clients also benefit from this project as they would want their loans to be approved by the Home Credit. They can fit themselves in the criteria to increase their chances of getting approval. However, the ‘bad’ people might also benefit because they will learn how to present themselves as someone having high repayment abilities in order to trick Home Credit. Our project is not intended for them, but for ‘regular’ clients. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c874b4f",
   "metadata": {},
   "source": [
    "# 9) Work-split\n",
    "*(This question is answered for you)*\n",
    "\n",
    "How do you plan to split the project work amongst individual team members?\n",
    "\n",
    "We will learn to develop and tune the following models in the STAT303 sequence:\n",
    "\n",
    "1. MARS\n",
    "\n",
    "2. Decision trees with cost-complexity pruning\n",
    "\n",
    "3. Bagging (Bagging MARS / decision trees) - Victoria Shi\n",
    "\n",
    "4. Random Forests - Victoria Shi\n",
    "\n",
    "5. AdaBoost\n",
    "\n",
    "6. Gradient boosting\n",
    "\n",
    "7. XGBoost\n",
    "\n",
    "8. Lasso / Ridge / Stepwise selection \n",
    "\n",
    "Each team member is required to develop and tune at least one of the above models. In the end, the team will combine all the developed models to create a model more accurate than each of the individual models.\n",
    "\n",
    "*(0 points)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
